

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Approximate Differential Privacy &#8212; Programming Differential Privacy</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Local Sensitivity" href="ch7.html" />
    <link rel="prev" title="Sensitivity" href="ch5.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Programming Differential Privacy</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../intro.html">Programming Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch1.html">De-identification & Re-Identification</a>
  </li>
  <li class="">
    <a href="ch2.html">k-Anonymity</a>
  </li>
  <li class="">
    <a href="ch3.html">Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch4.html">Properties of Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch5.html">Sensitivity</a>
  </li>
  <li class="active">
    <a href="">Approximate Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch7.html">Local Sensitivity</a>
  </li>
  <li class="">
    <a href="ch8.html">Variants of Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch9.html">The Exponential Mechanism</a>
  </li>
  <li class="">
    <a href="ch10.html">The Sparse Vector Technique</a>
  </li>
  <li class="">
    <a href="ch11.html">Exercises in Algorithm Design</a>
  </li>
  <li class="">
    <a href="ch12.html">Machine Learning with Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch13.html">Local Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch14.html">Differentially Private Synthetic Data</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/ch6.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#the-gaussian-mechanism" class="nav-link">The Gaussian Mechanism</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#vector-valued-functions-and-their-sensitivities" class="nav-link">Vector-Valued Functions and their Sensitivities</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#l1-and-l2-norms" class="nav-link">L1 and L2 Norms</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#l1-and-l2-sensitivities" class="nav-link">L1 and L2 Sensitivities</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#choosing-between-l1-and-l2" class="nav-link">Choosing Between L1 and L2</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#the-catastrophe-mechanism" class="nav-link">The Catastrophe Mechanism</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#advanced-composition" class="nav-link">Advanced Composition</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="approximate-differential-privacy">
<h1>Approximate Differential Privacy<a class="headerlink" href="#approximate-differential-privacy" title="Permalink to this headline">¶</a></h1>
<p>Approximate differential privacy, also called <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy, has the following definition:</p>
<p>\begin{align}
\mathsf{Pr}[F(x) = S] \leq e^\epsilon \mathsf{Pr}[F(x’) = s] + \delta
\end{align}</p>
<p>The new privacy parameter, <span class="math notranslate nohighlight">\(\delta\)</span>, represents a “failure probability” for the definition. With probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, we will get the same guarantee as pure differential privacy; with probability <span class="math notranslate nohighlight">\(\delta\)</span>, we get no guarantee. In other words:</p>
<ul class="simple">
<li><p>With probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, <span class="math notranslate nohighlight">\(\frac{\mathsf{Pr}[F(x) = S]}{\mathsf{Pr}[F(x') = s]} \leq e^\epsilon\)</span></p></li>
<li><p>With probability <span class="math notranslate nohighlight">\(\delta\)</span>, we get no guarantee at all</p></li>
</ul>
<p>This definition should seem a little bit scary! With probability <span class="math notranslate nohighlight">\(\delta\)</span>, anything at all could happen - including a release of the entire sensitive dataset! For this reason, we typically require <span class="math notranslate nohighlight">\(\delta\)</span> to be very small - usually <span class="math notranslate nohighlight">\(\frac{1}{n^2}\)</span> or less, where <span class="math notranslate nohighlight">\(n\)</span> is the size of the dataset. In addition, we’ll see that the <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differentially private mechanisms in practial use don’t fail catastrophically, as allowed by the definition - instead, they fail <em>gracefully</em>, and don’t do terrible things like releasing the entire dataset.</p>
<p>Such mechanisms <em>are</em> possible, however, and they do satisfy the definition of <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. We’ll see an example of such a mechanism later in this section.</p>
<div class="section" id="the-gaussian-mechanism">
<h2>The Gaussian Mechanism<a class="headerlink" href="#the-gaussian-mechanism" title="Permalink to this headline">¶</a></h2>
<p>The Gaussian mechanism is an alternative to the Laplace mechanism, which adds Gaussian noise instead of Laplacian noise. The Gaussian mechanism does <em>not</em> satisfy pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy, but does satisfy <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. According to the Gaussian mechanism, for a function <span class="math notranslate nohighlight">\(f(x)\)</span> which returns a number, the following definition of <span class="math notranslate nohighlight">\(F(x)\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy:</p>
<p>\begin{align}
F(x) = f(x) + \mathcal{N}(\sigma^2)\
\text{where } \sigma^2 = \frac{2s^2 \log(1.25/\delta)}{\epsilon^2}
\end{align}</p>
<p>where <span class="math notranslate nohighlight">\(s\)</span> is the sensitivity of <span class="math notranslate nohighlight">\(f\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{N}(\sigma^2)\)</span> denotes sampling from the Gaussian (normal) distribution with center 0 and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Note that here (and elsewhere in these notes), <span class="math notranslate nohighlight">\(\log\)</span> denotes the natural logarithm.</p>
<p>For real-valued functions <span class="math notranslate nohighlight">\(f : D \rightarrow \mathbb{R}\)</span>, we can use the Gaussian mechanism in exactly the same way as we do the Laplace mechanism, and it’s easy to compare what happens under both mechanisms for a given value of <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">vals_laplace</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">laplace</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span>

<span class="n">delta</span> <span class="o">=</span> <span class="mf">10e-5</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span> <span class="o">/</span> <span class="n">delta</span><span class="p">))</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">epsilon</span>
<span class="n">vals_gauss</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">vals_laplace</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Laplace&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">vals_gauss</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch6_4_0.png" src="../_images/ch6_4_0.png" />
</div>
</div>
<p>Here, we graph the empirical probability density function of the Laplace and Gaussian mechanisms for <span class="math notranslate nohighlight">\(\epsilon = 1\)</span>, with <span class="math notranslate nohighlight">\(\delta = 10^{-5}\)</span> for the Gaussian mechanism.</p>
<p>Compared to the Laplace mechanism, the plot for the Gaussian mechanism looks “squished.” Differentially private outputs which are far from the true answer are much more likely using the Gaussian mechanism than they are under the Laplace mechanism (which, by comparison, looks extremely “pointy”).</p>
<p>So the Gaussian mechanism has two major drawbacks - it requires the use of the the relaxed <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy definition, <em>and</em> it’s less accurate than the Laplace mechanism. Why would we want to use it?</p>
</div>
<div class="section" id="vector-valued-functions-and-their-sensitivities">
<h2>Vector-Valued Functions and their Sensitivities<a class="headerlink" href="#vector-valued-functions-and-their-sensitivities" title="Permalink to this headline">¶</a></h2>
<p>So far, we have only considered real-valued functions (i.e. the function’s output is always a single real number). Such functions are of the form <span class="math notranslate nohighlight">\(f : D \rightarrow \mathbb{R}\)</span>. Both the Laplace and Gaussian mechanism, however, can be extended to <em>vector-valued</em> functions of the form <span class="math notranslate nohighlight">\(f : D \rightarrow \mathbb{R}^k\)</span>, which return vectors of real numbers. We can think of histograms as vector-valued functions, which return a vector whose elements consist of histogram bin counts.</p>
<p>We saw earlier that the <em>sensitivity</em> of a function is:</p>
<p>\begin{align}
GS(f) = \max_{d(x,x’) \leq 1} \lvert f(x) - f(x’) \rvert
\end{align}</p>
<p>How do we define sensitivity for vector-valued functions?</p>
<p>Consider the expression <span class="math notranslate nohighlight">\(f(x) - f(x')\)</span>. If <span class="math notranslate nohighlight">\(f\)</span> is a vector-valued function, then this expression represents the difference between two vectors, which can be computed as the difference between their corresponding elements (the difference of two length-<span class="math notranslate nohighlight">\(k\)</span> vectors is thus a new length-<span class="math notranslate nohighlight">\(k\)</span> vector). This new vector is the distance between <span class="math notranslate nohighlight">\(f(x)\)</span> and <span class="math notranslate nohighlight">\(f(x')\)</span>, represented as a vector.</p>
<p>The magnitude of this vector is the sensitivity of <span class="math notranslate nohighlight">\(f\)</span>. There are several ways to compute the magnitude of a vector; we’ll use two of them: the <span class="math notranslate nohighlight">\(L1\)</span> norm and the <span class="math notranslate nohighlight">\(L2\)</span> norm.</p>
<div class="section" id="l1-and-l2-norms">
<h3>L1 and L2 Norms<a class="headerlink" href="#l1-and-l2-norms" title="Permalink to this headline">¶</a></h3>
<p>The <span class="math notranslate nohighlight">\(L1\)</span> norm of a vector <span class="math notranslate nohighlight">\(V\)</span> of length <span class="math notranslate nohighlight">\(k\)</span> is defined as <span class="math notranslate nohighlight">\(\lVert V \rVert_1 = \sum_{i=1}^k \lvert V_i \rvert\)</span> (i.e. it’s the sum of the vector’s elements). In 2-dimensional space, the <span class="math notranslate nohighlight">\(L1\)</span> norm of the difference between two vectors yields the “manhattan distance” between them.</p>
<p>The <span class="math notranslate nohighlight">\(L2\)</span> norm of a vector <span class="math notranslate nohighlight">\(V\)</span> of length <span class="math notranslate nohighlight">\(k\)</span> is defined as <span class="math notranslate nohighlight">\(\lVert V \rVert_2 = \sqrt{\sum_{i=1}^k V_i^2}\)</span> (i.e. the square root of the sum of the squares). In 2-dimensional space, this is the “Euclidian distance,” and it’s always less than or equal to the <span class="math notranslate nohighlight">\(L1\)</span> distance.</p>
</div>
<div class="section" id="l1-and-l2-sensitivities">
<h3>L1 and L2 Sensitivities<a class="headerlink" href="#l1-and-l2-sensitivities" title="Permalink to this headline">¶</a></h3>
<p>The <span class="math notranslate nohighlight">\(L1\)</span> sensitivity of a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> is:</p>
<p>\begin{align}
GS(f) = \max_{d(x,x’) \leq 1} \lVert f(x) - f(x’) \rVert_1
\end{align}</p>
<p>This is equal to the sum of the <em>elementwise</em> sensitivities. For example, if we define a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> that returns a length-<span class="math notranslate nohighlight">\(k\)</span> vector of 1-sensitive results, then the <span class="math notranslate nohighlight">\(L1\)</span> sensitivity of <span class="math notranslate nohighlight">\(f\)</span> is <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Similarly, the <span class="math notranslate nohighlight">\(L2\)</span> sensitivity of a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> is:</p>
<p>\begin{align}
GS_2(f) = \max_{d(x,x’) \leq 1} \lVert f(x) - f(x’) \rVert_2
\end{align}</p>
<p>Using the same example as above, a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> returning a length-<span class="math notranslate nohighlight">\(k\)</span> vector of 1-sensitive results has <span class="math notranslate nohighlight">\(L2\)</span> sensitivity of <span class="math notranslate nohighlight">\(\sqrt{k}\)</span>. For long vectors, the <span class="math notranslate nohighlight">\(L2\)</span> sensitivity will obviously be much lower than the <span class="math notranslate nohighlight">\(L1\)</span> sensitivity! For some applications, like machine learning algorithms (which sometimes return vectors with thousands of elements), <span class="math notranslate nohighlight">\(L2\)</span> sensitivity is <em>significantly</em> lower than <span class="math notranslate nohighlight">\(L1\)</span> sensitivity.</p>
</div>
<div class="section" id="choosing-between-l1-and-l2">
<h3>Choosing Between L1 and L2<a class="headerlink" href="#choosing-between-l1-and-l2" title="Permalink to this headline">¶</a></h3>
<p>As mentioned earlier, both the Laplace and Gaussian mechanisms can be extended to vector-valued functions. However, there’s a key difference between these two extensions: the vector-valued Laplace mechanism <strong>requires</strong> the use of <span class="math notranslate nohighlight">\(L1\)</span> sensitivity, while the vector-valued Gaussian mechanism allows the use of either <span class="math notranslate nohighlight">\(L1\)</span> or <span class="math notranslate nohighlight">\(L2\)</span> sensitivity. This is a major strength of the Gaussian mechanism. For applications in which <span class="math notranslate nohighlight">\(L2\)</span> sensitivity is much lower than <span class="math notranslate nohighlight">\(L1\)</span> sensitivity, the Gaussian mechansim allows adding <em>much</em> less noise.</p>
<ul class="simple">
<li><p>The <strong>vector-valued Laplace mechanism</strong> releases <span class="math notranslate nohighlight">\(f(x) + (Y_1, \dots, Y_k)\)</span>, where <span class="math notranslate nohighlight">\(Y_i\)</span> are drawn i.i.d. from the Laplace distribution with scale <span class="math notranslate nohighlight">\(\frac{s}{\epsilon}\)</span> and <span class="math notranslate nohighlight">\(s\)</span> is the <span class="math notranslate nohighlight">\(L1\)</span> sensitivity of <span class="math notranslate nohighlight">\(f\)</span></p></li>
<li><p>The <strong>vector-valued Gaussian mechanism</strong> releases <span class="math notranslate nohighlight">\(f(x) + (Y_1, \dots, Y_k)\)</span>, where <span class="math notranslate nohighlight">\(Y_i\)</span> are drawn i.i.d. from the Gaussian distribution with <span class="math notranslate nohighlight">\(\sigma^2 = \frac{2s^2 \log(1.25/\delta)}{\epsilon^2}\)</span> and <span class="math notranslate nohighlight">\(s\)</span> is the <span class="math notranslate nohighlight">\(L2\)</span> sensitivity of <span class="math notranslate nohighlight">\(f\)</span></p></li>
</ul>
</div>
</div>
<div class="section" id="the-catastrophe-mechanism">
<h2>The Catastrophe Mechanism<a class="headerlink" href="#the-catastrophe-mechanism" title="Permalink to this headline">¶</a></h2>
<p>The definition of <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy says that a mechanism which satisfies the definition must “behave well” with probability <span class="math notranslate nohighlight">\(1-\delta\)</span>. That means that with probability <span class="math notranslate nohighlight">\(\delta\)</span>, the mechanism can do anything at all. This “failure probability” is concerning, because mechanisms which satisfy the relaxed definition may (with low probability) result in very bad outcomes.</p>
<p>Consider the following mechanism, which we will call the <em>catastrophe mechansim</em>:</p>
<p>\begin{align}
F(q, x) =;&amp; \text{Sample a number <span class="math notranslate nohighlight">\(r\)</span> from the uniform distribution between 0 and 1}\
&amp;\text{If } r &lt; \delta, \text{return } x\
&amp;\text{Otherwise, return } q(x) + \text{Lap}(s/\epsilon), \text{where <span class="math notranslate nohighlight">\(s\)</span> is the sensitivity of <span class="math notranslate nohighlight">\(q\)</span>}\
\end{align}</p>
<p>With probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, the catastrophe mechanism satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy. With probability <span class="math notranslate nohighlight">\(\delta\)</span>, it <em>releases the whole dataset with no noise</em>. This mechanism satisfies the definition of approximate differential privacy, but we probably wouldn’t want to use it in practice.</p>
<p>Fortunately, most <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differentially private mechanisms don’t have such a catastrophic failure mode. The Gaussian mechanism, for example, doesn’t ever release the whole dataset. Instead, with probability <span class="math notranslate nohighlight">\(\delta\)</span>, the Gaussian mechanism doesn’t <em>quite</em> satisfy <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy - it satisfies <span class="math notranslate nohighlight">\(c\epsilon\)</span>-differential privacy instead, for some value <span class="math notranslate nohighlight">\(c\)</span>.</p>
<p>The Gaussian mechanism thus fails <em>gracefully</em>, rather than catistrophically, so it’s reasonable to have far more confidence in the Gaussian mechanism than in the catastrophe mechanism. Later, we will see alternative relaxations of the definition of differential privacy which distinguish between mechanisms that fail gracefully (like the Gaussian mechanism) and ones that fail catastropically (like the catastrophe mechanism).</p>
</div>
<div class="section" id="advanced-composition">
<h2>Advanced Composition<a class="headerlink" href="#advanced-composition" title="Permalink to this headline">¶</a></h2>
<p>We have already seen two ways of combining differentially private mechanisms: sequential composition and parallel composition. It turns out that <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy admits a new way of analyzing the sequential composition of differentially private mechanisms, which can result in a lower privacy cost.</p>
<p>The advanced composition theorem is usually stated in terms of mechanisms which are instances of <em><span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition</em>. A <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition is a sequence of mechanisms <span class="math notranslate nohighlight">\(m_1, \dots, m_k\)</span> such that:</p>
<ul class="simple">
<li><p>Each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> may be chosen based on the outputs of all previous mechanisms <span class="math notranslate nohighlight">\(m_1, \dots, m_{i-1}\)</span> (hence <em>adaptive</em>)</p></li>
<li><p>The input to each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> is both the private dataset and all of the outputs of previous mechanisms (hence <em>composition</em>)</p></li>
</ul>
<p>Iterative programs (i.e. loops or recursive functions) are nearly always instances of <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition. A <code class="docutils literal notranslate"><span class="pre">for</span></code> loop that runs 1000 iterations, for example, is a 1000-fold adaptive composition. As a more specific example, an averaging attack is a <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># works for sensitivity-1 queries</span>
<span class="k">def</span> <span class="nf">avg_attack</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">query</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">laplace</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">avg_attack</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>10.00639618152227
</pre></div>
</div>
</div>
</div>
<p>In this example, the sequence of mechanisms is fixed ahead of time (we use the same mechanism each time), and <span class="math notranslate nohighlight">\(k = 500\)</span>.</p>
<p>The standard sequential composition theorem says that the total privacy cost of this mechanism is <span class="math notranslate nohighlight">\(k\epsilon\)</span> (in this case, <span class="math notranslate nohighlight">\(500 \epsilon\)</span>).</p>
<p>The advanced composition theorem says:</p>
<ul class="simple">
<li><p>If each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> in a <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition <span class="math notranslate nohighlight">\(m_1, \dots, m_k\)</span> satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy</p></li>
<li><p>Then for <span class="math notranslate nohighlight">\(\epsilon', \delta \geq 0\)</span>, the total privacy cost of the entire <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition is equal to <span class="math notranslate nohighlight">\(\epsilon', \delta\)</span>, where:</p></li>
</ul>
<p>\begin{align}
\epsilon’ = 2\epsilon \sqrt{2k \log(1/\delta)}
\end{align}</p>
<p>Plugging in <span class="math notranslate nohighlight">\(\epsilon = 1\)</span> from the example above, and setting <span class="math notranslate nohighlight">\(\delta = 10^{-5}\)</span>, we get:</p>
<p>\begin{align}
\epsilon’ =&amp; 2 \sqrt{1000 \log(100000)}\
\approx&amp; 214.59
\end{align}</p>
<p>So advanced composition derives a much lower bound on <span class="math notranslate nohighlight">\(\epsilon'\)</span> than sequential composition, <em>for the same mechanism</em>.  What does this mean? It means that the bounds given by sequential composition are <em>loose</em> - they don’t tightly bound the <em>actual</em> privacy cost of the computation. In fact, advanced composition also gives loose bounds - they’re just slightly <em>less</em> loose than the ones given by sequential composition.</p>
<p>It’s important to note that the two bounds are technically incomparable, since advanced composition introduces a <span class="math notranslate nohighlight">\(\delta\)</span>. When <span class="math notranslate nohighlight">\(\delta\)</span> is small, however, we will often compare the <span class="math notranslate nohighlight">\(\epsilon\)</span>s given by both methods.</p>
<p>So, should we <em>always</em> use advanced composition? It turns out that we should <em>not</em>. Let’s try the experiment above for different values of <span class="math notranslate nohighlight">\(k\)</span>, and graph the <em>total privacy cost</em> under both sequential compsosition and advanced composition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">10e-5</span>

<span class="k">def</span> <span class="nf">adv_comp</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">epsilon</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">seq_comp</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">k</span><span class="o">*</span><span class="n">epsilon</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">seq_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">adv_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Advanced Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch6_11_0.png" src="../_images/ch6_11_0.png" />
</div>
</div>
<p>Standard sequential composition, it turns out, beats advanced composition for <span class="math notranslate nohighlight">\(k\)</span> smaller than about 70. Thus, advanced composition is only really useful when <span class="math notranslate nohighlight">\(k\)</span> is large (e.g. more than 100). When <span class="math notranslate nohighlight">\(k\)</span> is very large, though, advanced composition can make a <em>big</em> difference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">seq_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">adv_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Advanced Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch6_13_0.png" src="../_images/ch6_13_0.png" />
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ch5.html" title="previous page">Sensitivity</a>
    <a class='right-next' id="next-link" href="ch7.html" title="next page">Local Sensitivity</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Joseph P. Near<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>