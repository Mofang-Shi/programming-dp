
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Approximate Differential Privacy &#8212; Programming Differential Privacy</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Local Sensitivity" href="ch7.html" />
    <link rel="prev" title="Sensitivity" href="ch5.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Programming Differential Privacy</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="cover.html">
                    Programming Differential Privacy
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch1.html">
   De-identification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch2.html">
   k-Anonymity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch3.html">
   Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch4.html">
   Properties of Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch5.html">
   Sensitivity
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Approximate Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch7.html">
   Local Sensitivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch8.html">
   Variants of Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch9.html">
   The Exponential Mechanism
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch10.html">
   The Sparse Vector Technique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch11.html">
   Exercises in Algorithm Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch12.html">
   Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch13.html">
   Local Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch14.html">
   Synthetic Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/uvm-plaid/programming-dp/master?urlpath=tree/ch6.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/ch6.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-approximate-differential-privacy">
   Properties of Approximate Differential Privacy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-gaussian-mechanism">
   The Gaussian Mechanism
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vector-valued-functions-and-their-sensitivities">
   Vector-Valued Functions and their Sensitivities
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#l1-and-l2-norms">
     L1 and L2 Norms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#l1-and-l2-sensitivities">
     L1 and L2 Sensitivities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-between-l1-and-l2">
     Choosing Between L1 and L2
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-catastrophe-mechanism">
   The Catastrophe Mechanism
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-composition">
   Advanced Composition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-composition-for-approximate-differential-privacy">
   Advanced Composition for Approximate Differential Privacy
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Approximate Differential Privacy</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-approximate-differential-privacy">
   Properties of Approximate Differential Privacy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-gaussian-mechanism">
   The Gaussian Mechanism
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vector-valued-functions-and-their-sensitivities">
   Vector-Valued Functions and their Sensitivities
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#l1-and-l2-norms">
     L1 and L2 Norms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#l1-and-l2-sensitivities">
     L1 and L2 Sensitivities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#choosing-between-l1-and-l2">
     Choosing Between L1 and L2
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-catastrophe-mechanism">
   The Catastrophe Mechanism
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-composition">
   Advanced Composition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-composition-for-approximate-differential-privacy">
   Advanced Composition for Approximate Differential Privacy
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="approximate-differential-privacy">
<h1>Approximate Differential Privacy<a class="headerlink" href="#approximate-differential-privacy" title="Permalink to this headline">#</a></h1>
<div class="admonition-learning-objectives admonition">
<p class="admonition-title">Learning Objectives</p>
<p>After reading this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Define approximate differential privacy</p></li>
<li><p>Explain the differences between approximate and pure differential privacy</p></li>
<li><p>Describe the advantages and disadvantages of approximate differential privacy</p></li>
<li><p>Describe and calculate L1 and L2 sensitivity of vector-valued queries</p></li>
<li><p>Define and apply the Gaussian mechanism</p></li>
<li><p>Apply advanced composition</p></li>
</ul>
</div>
<p>Approximate differential privacy <span id="id1">[<a class="reference internal" href="bibliography.html#id5" title="Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: privacy via distributed noise generation. In Serge Vaudenay, editor, Advances in Cryptology - EUROCRYPT 2006, 486–503. Berlin, Heidelberg, 2006. Springer Berlin Heidelberg.">5</a>]</span>, also called <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy, has the following definition:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b54c7bd1-e45c-4e83-8c2f-6fa3693ae01c">
<span class="eqno">(6)<a class="headerlink" href="#equation-b54c7bd1-e45c-4e83-8c2f-6fa3693ae01c" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathsf{Pr}[F(x) = S] \leq e^\epsilon \mathsf{Pr}[F(x') = s] + \delta
\end{align}\]</div>
<p>The new privacy parameter, <span class="math notranslate nohighlight">\(\delta\)</span>, represents a “failure probability” for the definition. With probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, we will get the same guarantee as pure differential privacy; with probability <span class="math notranslate nohighlight">\(\delta\)</span>, we get no guarantee. In other words:</p>
<ul class="simple">
<li><p>With probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, <span class="math notranslate nohighlight">\(\frac{\mathsf{Pr}[F(x) = S]}{\mathsf{Pr}[F(x') = s]} \leq e^\epsilon\)</span></p></li>
<li><p>With probability <span class="math notranslate nohighlight">\(\delta\)</span>, we get no guarantee at all</p></li>
</ul>
<p>This definition should seem a little bit scary! With probability <span class="math notranslate nohighlight">\(\delta\)</span>, anything at all could happen - including a release of the entire sensitive dataset! For this reason, we typically require <span class="math notranslate nohighlight">\(\delta\)</span> to be very small - usually <span class="math notranslate nohighlight">\(\frac{1}{n^2}\)</span> or less, where <span class="math notranslate nohighlight">\(n\)</span> is the size of the dataset. In addition, we’ll see that the <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differentially private mechanisms in practical use don’t fail catastrophically, as allowed by the definition - instead, they fail <em>gracefully</em>, and don’t do terrible things like releasing the entire dataset.</p>
<p>Such mechanisms <em>are</em> possible, however, and they do satisfy the definition of <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. We’ll see an example of such a mechanism later in this section.</p>
<div class="section" id="properties-of-approximate-differential-privacy">
<h2>Properties of Approximate Differential Privacy<a class="headerlink" href="#properties-of-approximate-differential-privacy" title="Permalink to this headline">#</a></h2>
<p>Approximate differential privacy has similar properties to pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy. It satisfies <strong>sequential composition</strong>:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(F_1(x)\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon_1, \delta_1)\)</span>-differential privacy</p></li>
<li><p>And <span class="math notranslate nohighlight">\(F_2(x)\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon_2, \delta_2)\)</span>-differential privacy</p></li>
<li><p>Then the mechanism <span class="math notranslate nohighlight">\(G(x) = (F_1(x), F_2(x))\)</span> which releases both results satisfies <span class="math notranslate nohighlight">\((\epsilon_1+\epsilon_2, \delta_1 + \delta_2)\)</span>-differential privacy</p></li>
</ul>
<p>The only difference from the pure <span class="math notranslate nohighlight">\(\epsilon\)</span> setting is that we add up the <span class="math notranslate nohighlight">\(\delta\)</span>s as well as the <span class="math notranslate nohighlight">\(\epsilon\)</span>s. Approximate differential privacy also satisfies post-processing and parallel composition.</p>
</div>
<div class="section" id="the-gaussian-mechanism">
<h2>The Gaussian Mechanism<a class="headerlink" href="#the-gaussian-mechanism" title="Permalink to this headline">#</a></h2>
<p>The Gaussian mechanism is an alternative to the Laplace mechanism, which adds Gaussian noise instead of Laplacian noise. The Gaussian mechanism does <em>not</em> satisfy pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy, but does satisfy <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. According to the Gaussian mechanism, for a function <span class="math notranslate nohighlight">\(f(x)\)</span> which returns a number, the following definition of <span class="math notranslate nohighlight">\(F(x)\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5bb8dc41-77b4-480d-a8c4-f8f100886c60">
<span class="eqno">(7)<a class="headerlink" href="#equation-5bb8dc41-77b4-480d-a8c4-f8f100886c60" title="Permalink to this equation">#</a></span>\[\begin{align}
F(x) = f(x) + \mathcal{N}(\sigma^2)\\
\text{where } \sigma^2 = \frac{2s^2 \log(1.25/\delta)}{\epsilon^2}
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(s\)</span> is the sensitivity of <span class="math notranslate nohighlight">\(f\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{N}(\sigma^2)\)</span> denotes sampling from the Gaussian (normal) distribution with center 0 and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Note that here (and elsewhere in these notes), <span class="math notranslate nohighlight">\(\log\)</span> denotes the natural logarithm.</p>
<p>For real-valued functions <span class="math notranslate nohighlight">\(f : D \rightarrow \mathbb{R}\)</span>, we can use the Gaussian mechanism in exactly the same way as we do the Laplace mechanism, and it’s easy to compare what happens under both mechanisms for a given value of <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">vals_laplace</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">laplace</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span>

<span class="n">delta</span> <span class="o">=</span> <span class="mf">10e-5</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span> <span class="o">/</span> <span class="n">delta</span><span class="p">))</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">epsilon</span>
<span class="n">vals_gauss</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">vals_laplace</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Laplace&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">vals_gauss</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ch6_5_0.png" src="_images/ch6_5_0.png" />
</div>
</div>
<p>Here, we graph the empirical probability density function of the Laplace and Gaussian mechanisms for <span class="math notranslate nohighlight">\(\epsilon = 1\)</span>, with <span class="math notranslate nohighlight">\(\delta = 10^{-5}\)</span> for the Gaussian mechanism.</p>
<p>Compared to the Laplace mechanism, the plot for the Gaussian mechanism looks “squished.” Differentially private outputs which are far from the true answer are much more likely using the Gaussian mechanism than they are under the Laplace mechanism (which, by comparison, looks extremely “pointy”).</p>
<p>So the Gaussian mechanism has two major drawbacks - it requires the use of the the relaxed <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy definition, <em>and</em> it’s less accurate than the Laplace mechanism. Why would we want to use it?</p>
</div>
<div class="section" id="vector-valued-functions-and-their-sensitivities">
<h2>Vector-Valued Functions and their Sensitivities<a class="headerlink" href="#vector-valued-functions-and-their-sensitivities" title="Permalink to this headline">#</a></h2>
<p>So far, we have only considered real-valued functions (i.e. the function’s output is always a single real number). Such functions are of the form <span class="math notranslate nohighlight">\(f : D \rightarrow \mathbb{R}\)</span>. Both the Laplace and Gaussian mechanism, however, can be extended to <em>vector-valued</em> functions of the form <span class="math notranslate nohighlight">\(f : D \rightarrow \mathbb{R}^k\)</span>, which return vectors of real numbers. We can think of histograms as vector-valued functions, which return a vector whose elements consist of histogram bin counts.</p>
<p>We saw earlier that the <em>sensitivity</em> of a function is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-04ce9598-9f8c-44b1-a824-0a3839f6e543">
<span class="eqno">(8)<a class="headerlink" href="#equation-04ce9598-9f8c-44b1-a824-0a3839f6e543" title="Permalink to this equation">#</a></span>\[\begin{align}
GS(f) = \max_{d(x,x') \leq 1} \lvert f(x) - f(x') \rvert
\end{align}\]</div>
<p>How do we define sensitivity for vector-valued functions?</p>
<p>Consider the expression <span class="math notranslate nohighlight">\(f(x) - f(x')\)</span>. If <span class="math notranslate nohighlight">\(f\)</span> is a vector-valued function, then this expression represents the difference between two vectors, which can be computed as the difference between their corresponding elements (the difference of two length-<span class="math notranslate nohighlight">\(k\)</span> vectors is thus a new length-<span class="math notranslate nohighlight">\(k\)</span> vector). This new vector is the distance between <span class="math notranslate nohighlight">\(f(x)\)</span> and <span class="math notranslate nohighlight">\(f(x')\)</span>, represented as a vector.</p>
<p>The magnitude of this vector is the sensitivity of <span class="math notranslate nohighlight">\(f\)</span>. There are several ways to compute the magnitude of a vector; we’ll use two of them: the <span class="math notranslate nohighlight">\(L1\)</span> norm and the <span class="math notranslate nohighlight">\(L2\)</span> norm.</p>
<div class="section" id="l1-and-l2-norms">
<h3>L1 and L2 Norms<a class="headerlink" href="#l1-and-l2-norms" title="Permalink to this headline">#</a></h3>
<p>The <span class="math notranslate nohighlight">\(L1\)</span> norm of a vector <span class="math notranslate nohighlight">\(V\)</span> of length <span class="math notranslate nohighlight">\(k\)</span> is defined as <span class="math notranslate nohighlight">\(\lVert V \rVert_1 = \sum_{i=1}^k \lvert V_i \rvert\)</span> (i.e. it’s the sum of the vector’s elements). In 2-dimensional space, the <span class="math notranslate nohighlight">\(L1\)</span> norm of the difference between two vectors yields the “manhattan distance” between them.</p>
<p>The <span class="math notranslate nohighlight">\(L2\)</span> norm of a vector <span class="math notranslate nohighlight">\(V\)</span> of length <span class="math notranslate nohighlight">\(k\)</span> is defined as <span class="math notranslate nohighlight">\(\lVert V \rVert_2 = \sqrt{\sum_{i=1}^k V_i^2}\)</span> (i.e. the square root of the sum of the squares). In 2-dimensional space, this is the “Euclidean distance”, and it’s always less than or equal to the <span class="math notranslate nohighlight">\(L1\)</span> norm.</p>
</div>
<div class="section" id="l1-and-l2-sensitivities">
<h3>L1 and L2 Sensitivities<a class="headerlink" href="#l1-and-l2-sensitivities" title="Permalink to this headline">#</a></h3>
<p>The <span class="math notranslate nohighlight">\(L1\)</span> sensitivity of a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1a9174ae-3d64-4422-8f25-563ca72d4162">
<span class="eqno">(9)<a class="headerlink" href="#equation-1a9174ae-3d64-4422-8f25-563ca72d4162" title="Permalink to this equation">#</a></span>\[\begin{align}
GS(f) = \max_{d(x,x') \leq 1} \lVert f(x) - f(x') \rVert_1
\end{align}\]</div>
<p>This is equal to the sum of the <em>elementwise</em> sensitivities. For example, if we define a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> that returns a length-<span class="math notranslate nohighlight">\(k\)</span> vector of 1-sensitive results, then the <span class="math notranslate nohighlight">\(L1\)</span> sensitivity of <span class="math notranslate nohighlight">\(f\)</span> is <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Similarly, the <span class="math notranslate nohighlight">\(L2\)</span> sensitivity of a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-44d367af-2b6f-48f0-90d5-7d6fc1571e90">
<span class="eqno">(10)<a class="headerlink" href="#equation-44d367af-2b6f-48f0-90d5-7d6fc1571e90" title="Permalink to this equation">#</a></span>\[\begin{align}
GS_2(f) = \max_{d(x,x') \leq 1} \lVert f(x) - f(x') \rVert_2
\end{align}\]</div>
<p>Using the same example as above, a vector-valued function <span class="math notranslate nohighlight">\(f\)</span> returning a length-<span class="math notranslate nohighlight">\(k\)</span> vector of 1-sensitive results has <span class="math notranslate nohighlight">\(L2\)</span> sensitivity of <span class="math notranslate nohighlight">\(\sqrt{k}\)</span>. For long vectors, the <span class="math notranslate nohighlight">\(L2\)</span> sensitivity will obviously be much lower than the <span class="math notranslate nohighlight">\(L1\)</span> sensitivity! For some applications, like machine learning algorithms (which sometimes return vectors with thousands of elements), <span class="math notranslate nohighlight">\(L2\)</span> sensitivity is <em>significantly</em> lower than <span class="math notranslate nohighlight">\(L1\)</span> sensitivity.</p>
</div>
<div class="section" id="choosing-between-l1-and-l2">
<h3>Choosing Between L1 and L2<a class="headerlink" href="#choosing-between-l1-and-l2" title="Permalink to this headline">#</a></h3>
<p>As mentioned earlier, both the Laplace and Gaussian mechanisms can be extended to vector-valued functions. However, there’s a key difference between these two extensions: the vector-valued Laplace mechanism <strong>requires</strong> the use of <span class="math notranslate nohighlight">\(L1\)</span> sensitivity, while the vector-valued Gaussian mechanism allows the use of either <span class="math notranslate nohighlight">\(L1\)</span> or <span class="math notranslate nohighlight">\(L2\)</span> sensitivity. This is a major strength of the Gaussian mechanism. For applications in which <span class="math notranslate nohighlight">\(L2\)</span> sensitivity is much lower than <span class="math notranslate nohighlight">\(L1\)</span> sensitivity, the Gaussian mechansim allows adding <em>much</em> less noise.</p>
<ul class="simple">
<li><p>The <strong>vector-valued Laplace mechanism</strong> releases <span class="math notranslate nohighlight">\(f(x) + (Y_1, \dots, Y_k)\)</span>, where <span class="math notranslate nohighlight">\(Y_i\)</span> are drawn i.i.d. from the Laplace distribution with scale <span class="math notranslate nohighlight">\(\frac{s}{\epsilon}\)</span> and <span class="math notranslate nohighlight">\(s\)</span> is the <span class="math notranslate nohighlight">\(L1\)</span> sensitivity of <span class="math notranslate nohighlight">\(f\)</span></p></li>
<li><p>The <strong>vector-valued Gaussian mechanism</strong> releases <span class="math notranslate nohighlight">\(f(x) + (Y_1, \dots, Y_k)\)</span>, where <span class="math notranslate nohighlight">\(Y_i\)</span> are drawn i.i.d. from the Gaussian distribution with <span class="math notranslate nohighlight">\(\sigma^2 = \frac{2s^2 \log(1.25/\delta)}{\epsilon^2}\)</span> and <span class="math notranslate nohighlight">\(s\)</span> is the <span class="math notranslate nohighlight">\(L2\)</span> sensitivity of <span class="math notranslate nohighlight">\(f\)</span></p></li>
</ul>
</div>
</div>
<div class="section" id="the-catastrophe-mechanism">
<h2>The Catastrophe Mechanism<a class="headerlink" href="#the-catastrophe-mechanism" title="Permalink to this headline">#</a></h2>
<p>The definition of <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy says that a mechanism which satisfies the definition must “behave well” with probability <span class="math notranslate nohighlight">\(1-\delta\)</span>. That means that with probability <span class="math notranslate nohighlight">\(\delta\)</span>, the mechanism can do anything at all. This “failure probability” is concerning, because mechanisms which satisfy the relaxed definition may (with low probability) result in very bad outcomes.</p>
<p>Consider the following mechanism, which we will call the <em>catastrophe mechanism</em>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d4db6203-c130-4737-b145-c3fcfbe41b4f">
<span class="eqno">(11)<a class="headerlink" href="#equation-d4db6203-c130-4737-b145-c3fcfbe41b4f" title="Permalink to this equation">#</a></span>\[\begin{align}
F(q, x) =\;&amp; \text{Sample a number $r$ from the uniform distribution between 0 and 1}\\
&amp;\text{If } r &lt; \delta, \text{return } x\\
&amp;\text{Otherwise, return } q(x) + \text{Lap}(s/\epsilon), \text{where $s$ is the sensitivity of $q$}\\
\end{align}\]</div>
<p>With probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, the catastrophe mechanism satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy. With probability <span class="math notranslate nohighlight">\(\delta\)</span>, it <em>releases the whole dataset with no noise</em>. This mechanism satisfies the definition of approximate differential privacy, but we probably wouldn’t want to use it in practice.</p>
<p>Fortunately, most <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differentially private mechanisms don’t have such a catastrophic failure mode. The Gaussian mechanism, for example, doesn’t ever release the whole dataset. Instead, with probability <span class="math notranslate nohighlight">\(\delta\)</span>, the Gaussian mechanism doesn’t <em>quite</em> satisfy <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy - it satisfies <span class="math notranslate nohighlight">\(c\epsilon\)</span>-differential privacy instead, for some value <span class="math notranslate nohighlight">\(c\)</span>.</p>
<p>The Gaussian mechanism thus fails <em>gracefully</em>, rather than catastrophically, so it’s reasonable to have far more confidence in the Gaussian mechanism than in the catastrophe mechanism. Later, we will see alternative relaxations of the definition of differential privacy which distinguish between mechanisms that fail gracefully (like the Gaussian mechanism) and ones that fail catastropically (like the catastrophe mechanism).</p>
</div>
<div class="section" id="advanced-composition">
<h2>Advanced Composition<a class="headerlink" href="#advanced-composition" title="Permalink to this headline">#</a></h2>
<p>We have already seen two ways of combining differentially private mechanisms: sequential composition and parallel composition. It turns out that <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy admits a new way of analyzing the sequential composition of differentially private mechanisms, which can result in a lower privacy cost.</p>
<p>The advanced composition theorem <span id="id2">[<a class="reference internal" href="bibliography.html#id11" title="Cynthia Dwork, Guy N. Rothblum, and Salil Vadhan. Boosting and differential privacy. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, volume, 51-60. 2010. doi:10.1109/FOCS.2010.12.">7</a>]</span> is usually stated in terms of mechanisms which are instances of <em><span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition</em>. A <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition is a sequence of mechanisms <span class="math notranslate nohighlight">\(m_1, \dots, m_k\)</span> such that:</p>
<ul class="simple">
<li><p>Each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> may be chosen based on the outputs of all previous mechanisms <span class="math notranslate nohighlight">\(m_1, \dots, m_{i-1}\)</span> (hence <em>adaptive</em>)</p></li>
<li><p>The input to each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> is both the private dataset and all of the outputs of previous mechanisms (hence <em>composition</em>)</p></li>
</ul>
<p>Iterative programs (i.e. loops or recursive functions) are nearly always instances of <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition. A <code class="docutils literal notranslate"><span class="pre">for</span></code> loop that runs 1000 iterations, for example, is a 1000-fold adaptive composition. As a more specific example, an averaging attack is a <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># works for sensitivity-1 queries</span>
<span class="k">def</span> <span class="nf">avg_attack</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">query</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">laplace</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">avg_attack</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10.035861155178825
</pre></div>
</div>
</div>
</div>
<p>In this example, the sequence of mechanisms is fixed ahead of time (we use the same mechanism each time), and <span class="math notranslate nohighlight">\(k = 500\)</span>.</p>
<p>The standard sequential composition theorem says that the total privacy cost of this mechanism is <span class="math notranslate nohighlight">\(k\epsilon\)</span> (in this case, <span class="math notranslate nohighlight">\(500 \epsilon\)</span>).</p>
<p>The advanced composition theorem says:</p>
<ul class="simple">
<li><p>If each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> in a <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition <span class="math notranslate nohighlight">\(m_1, \dots, m_k\)</span> satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy</p></li>
<li><p>Then for any <span class="math notranslate nohighlight">\(\delta \geq 0\)</span>, the entire <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition satisfies <span class="math notranslate nohighlight">\((\epsilon', \delta')\)</span>-differential privacy, where:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-3b47bdd6-f86c-4565-9ab2-00277929b046">
<span class="eqno">(12)<a class="headerlink" href="#equation-3b47bdd6-f86c-4565-9ab2-00277929b046" title="Permalink to this equation">#</a></span>\[\begin{align}
\epsilon' = 2\epsilon \sqrt{2k \log(1/\delta')}
\end{align}\]</div>
<p>Plugging in <span class="math notranslate nohighlight">\(\epsilon = 1\)</span> from the example above, and setting <span class="math notranslate nohighlight">\(\delta' = 10^{-5}\)</span>, we get:</p>
<div class="amsmath math notranslate nohighlight" id="equation-67e41353-2696-4036-91a8-33b00f977a37">
<span class="eqno">(13)<a class="headerlink" href="#equation-67e41353-2696-4036-91a8-33b00f977a37" title="Permalink to this equation">#</a></span>\[\begin{align}
\epsilon' =&amp; 2 \sqrt{1000 \log(100000)}\\
\approx&amp; 214.59
\end{align}\]</div>
<p>So advanced composition derives a much lower bound on <span class="math notranslate nohighlight">\(\epsilon'\)</span> than sequential composition, <em>for the same mechanism</em>.  What does this mean? It means that the bounds given by sequential composition are <em>loose</em> - they don’t tightly bound the <em>actual</em> privacy cost of the computation. In fact, advanced composition also gives loose bounds - they’re just slightly <em>less</em> loose than the ones given by sequential composition.</p>
<p>It’s important to note that the two bounds are technically incomparable, since advanced composition introduces a <span class="math notranslate nohighlight">\(\delta\)</span>. When <span class="math notranslate nohighlight">\(\delta\)</span> is small, however, we will often compare the <span class="math notranslate nohighlight">\(\epsilon\)</span>s given by both methods.</p>
<p>So, should we <em>always</em> use advanced composition? It turns out that we should <em>not</em>. Let’s try the experiment above for different values of <span class="math notranslate nohighlight">\(k\)</span>, and graph the <em>total privacy cost</em> under both sequential composition and advanced composition.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">10e-5</span>

<span class="k">def</span> <span class="nf">adv_comp</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">epsilon</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">seq_comp</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">k</span><span class="o">*</span><span class="n">epsilon</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">seq_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">adv_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Advanced Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ch6_12_0.png" src="_images/ch6_12_0.png" />
</div>
</div>
<p>Standard sequential composition, it turns out, beats advanced composition for <span class="math notranslate nohighlight">\(k\)</span> smaller than about 70. Thus, advanced composition is only really useful when <span class="math notranslate nohighlight">\(k\)</span> is large (e.g. more than 100). When <span class="math notranslate nohighlight">\(k\)</span> is very large, though, advanced composition can make a <em>big</em> difference.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">seq_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">adv_comp</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Advanced Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ch6_14_0.png" src="_images/ch6_14_0.png" />
</div>
</div>
</div>
<div class="section" id="advanced-composition-for-approximate-differential-privacy">
<h2>Advanced Composition for Approximate Differential Privacy<a class="headerlink" href="#advanced-composition-for-approximate-differential-privacy" title="Permalink to this headline">#</a></h2>
<p>The description of advanced composition above requires the individual mechanisms being composed to satisfy pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy. However, the theorem also applies if they satisfy <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy instead. The more general statement of the advanced composition theorem is as follows (<span id="id3">[<a class="reference internal" href="bibliography.html#id11" title="Cynthia Dwork, Guy N. Rothblum, and Salil Vadhan. Boosting and differential privacy. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, volume, 51-60. 2010. doi:10.1109/FOCS.2010.12.">7</a>]</span>, Theorem 3.20):</p>
<ul class="simple">
<li><p>If each mechanism <span class="math notranslate nohighlight">\(m_i\)</span> in a <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition <span class="math notranslate nohighlight">\(m_1, \dots, m_k\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy</p></li>
<li><p>Then for any <span class="math notranslate nohighlight">\(\delta' \geq 0\)</span>, the entire <span class="math notranslate nohighlight">\(k\)</span>-fold adaptive composition satisfies <span class="math notranslate nohighlight">\((\epsilon', k\delta + \delta')\)</span>-differential privacy, where:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-9658ca5f-c685-4146-9abc-17c42ccf19d6">
<span class="eqno">(14)<a class="headerlink" href="#equation-9658ca5f-c685-4146-9abc-17c42ccf19d6" title="Permalink to this equation">#</a></span>\[\begin{align}
\epsilon' = 2\epsilon \sqrt{2k \log(1/\delta')}
\end{align}\]</div>
<p>The only difference is in the failure parameter <span class="math notranslate nohighlight">\(\delta\)</span> for the composed mechanism, where we have an additional <span class="math notranslate nohighlight">\(k\delta\)</span> term. When the mechanisms being composed satisfy pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy, then <span class="math notranslate nohighlight">\(\delta = k\delta = 0\)</span>, and we get the same result as the statement above.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ch5.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Sensitivity</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="ch7.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Local Sensitivity</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Joseph P. Near and Chiké Abuah<br/>
  
      &copy; Copyright 2021.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>